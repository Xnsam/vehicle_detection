{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vehicle_detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndruBl6L6Dhq",
        "colab_type": "text"
      },
      "source": [
        "References : https://github.com/NikolasEnt/Vehicle-Detection-and-Tracking/blob/master/VehicheDetect.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8V0E8hP6GvM",
        "colab_type": "text"
      },
      "source": [
        "Data: \n",
        "\n",
        "https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/vehicles.zip\n",
        "\n",
        "https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/non-vehicles.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3WXsphV6XOk",
        "colab_type": "text"
      },
      "source": [
        "# Existing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j5GGueI6C-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
        "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
        "    # If x and/or y start/stop positions not defined, set to image size\n",
        "    if x_start_stop[0] == None:\n",
        "        x_start_stop[0] = 0\n",
        "    if x_start_stop[1] == None:\n",
        "        x_start_stop[1] = img.shape[1]\n",
        "    if y_start_stop[0] == None:\n",
        "        y_start_stop[0] = 0\n",
        "    if y_start_stop[1] == None:\n",
        "        y_start_stop[1] = img.shape[0]\n",
        "    # Compute the span of the region to be searched    \n",
        "    xspan = x_start_stop[1] - x_start_stop[0]\n",
        "    yspan = y_start_stop[1] - y_start_stop[0]\n",
        "    # Compute the number of pixels per step in x/y\n",
        "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
        "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
        "    # Compute the number of windows in x/y\n",
        "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
        "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
        "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
        "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
        "    # Initialize a list to append window positions to\n",
        "    window_list = []\n",
        "    # Loop through finding x and y window positions\n",
        "    # Note: you could vectorize this step, but in practice\n",
        "    # you'll be considering windows one by one with your\n",
        "    # classifier, so looping makes sense\n",
        "    for ys in range(ny_windows):\n",
        "        for xs in range(nx_windows):\n",
        "            # Calculate window position\n",
        "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
        "            endx = startx + xy_window[0]\n",
        "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
        "            endy = starty + xy_window[1]\n",
        "            # Append window position to list\n",
        "            window_list.append(((startx, starty), (endx, endy)))\n",
        "    # Return the list of windows\n",
        "    return window_list\n",
        "\n",
        "# Define a function to draw bounding boxes on an image\n",
        "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
        "    imcopy = np.copy(img) # Make a copy of the image\n",
        "    for bbox in bboxes: # Iterate through the bounding boxes\n",
        "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
        "    return imcopy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6XjXcFT5y1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def single_img_features(img, color_space='RGB', spatial_size=(32, 32),\n",
        "                        hist_bins=32, orient=9, \n",
        "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
        "                        spatial_feat=True, hist_feat=True, hog_feat=True):    \n",
        "    #1) Define an empty list to receive features\n",
        "    img_features = []\n",
        "    #2) Apply color conversion if other than 'RGB'\n",
        "    if color_space != 'RGB':\n",
        "        if color_space == 'HSV':\n",
        "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "        elif color_space == 'LUV':\n",
        "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
        "        elif color_space == 'HLS':\n",
        "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
        "        elif color_space == 'YUV':\n",
        "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
        "        elif color_space == 'YCrCb':\n",
        "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
        "    else: feature_image = np.copy(img)      \n",
        "    #3) Compute spatial features if flag is set\n",
        "    if spatial_feat == True:\n",
        "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
        "        #4) Append features to list\n",
        "        img_features.append(spatial_features)\n",
        "    #5) Compute histogram features if flag is set\n",
        "    if hist_feat == True:\n",
        "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
        "        #6) Append features to list\n",
        "        img_features.append(hist_features)\n",
        "    #7) Compute HOG features if flag is set\n",
        "    if hog_feat == True:\n",
        "        if hog_channel == 'ALL':\n",
        "            hog_features = []\n",
        "            for channel in range(feature_image.shape[2]):\n",
        "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
        "                                    orient, pix_per_cell, cell_per_block, \n",
        "                                    vis=False, feature_vec=True))      \n",
        "        else:\n",
        "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
        "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
        "        #8) Append features to list\n",
        "        img_features.append(hog_features)\n",
        "    #9) Return concatenated array of features\n",
        "    return np.concatenate(img_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uQdHnT16hwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Define a function you will pass an image \n",
        "# and the list of windows to be searched (output of slide_windows())\n",
        "def search_windows(img, windows, clf, scaler, color_space='RGB', \n",
        "                    spatial_size=(32, 32), hist_bins=32, \n",
        "                    hist_range=(0, 256), orient=8, \n",
        "                    pix_per_cell=8, cell_per_block=2, \n",
        "                    hog_channel=0, spatial_feat=True, \n",
        "                    hist_feat=True, hog_feat=True):\n",
        "\n",
        "    #1) Create an empty list to receive positive detection windows\n",
        "    on_windows = []\n",
        "    #2) Iterate over all windows in the list\n",
        "    for window in windows:\n",
        "        #3) Extract the test window from original image\n",
        "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
        "        #4) Extract features for that window using single_img_features()\n",
        "        features = single_img_features(test_img, color_space=color_space, \n",
        "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
        "                            orient=orient, pix_per_cell=pix_per_cell, \n",
        "                            cell_per_block=cell_per_block, \n",
        "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
        "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
        "        #5) Scale extracted features to be fed to classifier\n",
        "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
        "        #6) Predict using your classifier\n",
        "        prediction = clf.predict(test_features)\n",
        "        #7) If positive (prediction == 1) then save the window\n",
        "        if prediction == 1:\n",
        "            on_windows.append(window)\n",
        "    #8) Return windows for positive detections\n",
        "    return on_windows\n",
        "\n",
        "# A function to show an image\n",
        "def show_img(img):\n",
        "    if len(img.shape)==3: #Color BGR image\n",
        "        plt.figure()\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    else: # Grayscale image\n",
        "        plt.figure()\n",
        "        plt.imshow(img, cmap='gray')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LItEoGI6hth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gpAn9It6hmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}